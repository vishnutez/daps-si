name: ldm

ldm_config:                                                     # Don't modify this part
  model:
    base_learning_rate: 2.0e-06
    target: model.ldm.models.diffusion.ddpm.LatentDiffusion
    params:
      linear_start: 0.0015
      linear_end: 0.0195
      num_timesteps_cond: 1
      log_every_t: 200
      timesteps: 1000
      first_stage_key: image
      image_size: 64
      channels: 3
      monitor: val/loss_simple_ema
      unet_config:
        target: model.ldm.modules.diffusionmodules.openaimodel.UNetModel
        params:
          image_size: 64
          in_channels: 3
          out_channels: 3
          model_channels: 224
          attention_resolutions: [8, 4, 2]
          num_res_blocks: 2
          channel_mult: [1, 2, 3, 4]
          num_head_channels: 32
      first_stage_config:
        target: model.ldm.models.autoencoder.VQModelInterface
        params:
          embed_dim: 3
          n_embed: 8192
          ckpt_path: null
          ddconfig:
            double_z: false
            z_channels: 3
            resolution: 256
            in_channels: 3
            out_ch: 3
            ch: 128
            ch_mult:
            - 1
            - 2
            - 4
            num_res_blocks: 2
            attn_resolutions: []
            dropout: 0.0
          lossconfig:
            target: torch.nn.Identity
      cond_stage_config: __is_unconditional__ 
diffusion_path: 'checkpoints/ldm_ffhq256.pt'                    # Change here to right path to the LDM model